{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4883ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "458d40b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "                                                  URL  \\\n",
      "0   https://academic.oup.com/bib/article-abstract/...   \n",
      "1   https://www.researchgate.net/profile/Bo-Zhao-3...   \n",
      "2                 http://ir.kdu.ac.lk/handle/345/1051   \n",
      "3   https://books.google.com/books?hl=en&lr=&id=TY...   \n",
      "4   http://ijasca.zuj.edu.jo/PapersUploaded/2021.3...   \n",
      "5   https://books.google.com/books?hl=en&lr=&id=V_...   \n",
      "6   https://www.researchgate.net/profile/Vlad-Krot...   \n",
      "7   https://digitalcommons.murraystate.edu/faculty...   \n",
      "8   https://ieeexplore.ieee.org/abstract/document/...   \n",
      "9   https://books.google.com/books?hl=en&lr=&id=hO...   \n",
      "10  https://www.academia.edu/download/30571939/139...   \n",
      "11  https://ieeexplore.ieee.org/abstract/document/...   \n",
      "12  https://www.unwe.bg/uploads/Alternatives/10_Al...   \n",
      "13  https://ieeexplore.ieee.org/abstract/document/...   \n",
      "14  https://ieeexplore.ieee.org/abstract/document/...   \n",
      "15     https://psycnet.apa.org/journals/met/21/4/475/   \n",
      "16  https://books.google.com/books?hl=en&lr=&id=jH...   \n",
      "17  https://ieeexplore.ieee.org/abstract/document/...   \n",
      "18  https://www.perkinscoie.com/images/content/1/5...   \n",
      "19  https://www.bigsurv.org/bigsurv18/uploads/73/6...   \n",
      "20  https://citeseerx.ist.psu.edu/document?repid=r...   \n",
      "21  https://link.springer.com/chapter/10.1007/978-...   \n",
      "22      http://www2.imm.dtu.dk/pubdb/edoc/imm6183.pdf   \n",
      "23  http://rochi.utcluj.ro/rrioc/articole/RRIOC-11...   \n",
      "24  https://dl.acm.org/doi/abs/10.1145/2487788.248...   \n",
      "25  https://www.tandfonline.com/doi/abs/10.1080/10...   \n",
      "26  https://www.tandfonline.com/doi/abs/10.1080/13...   \n",
      "27  https://heinonline.org/hol-cgi-bin/get_pdf.cgi...   \n",
      "28  https://link.springer.com/chapter/10.1007/978-...   \n",
      "29  https://content.iospress.com/articles/statisti...   \n",
      "\n",
      "                                                Title  \\\n",
      "0           Web scraping technologies in an API world   \n",
      "1                                        Web scraping   \n",
      "2                 A comparative study on web scraping   \n",
      "3   Web scraping with Python: Collecting more data...   \n",
      "4   Web Scraping or Web Crawling: State of Art, Te...   \n",
      "5                            Web scraping with Python   \n",
      "6                 Legality and ethics of web scraping   \n",
      "7       Tutorial: Legality and ethics of web scraping   \n",
      "8   Web scraping: state-of-the-art and areas of ap...   \n",
      "9   Automated data collection with R: A practical ...   \n",
      "10  Exploiting web scraping in a collaborative fil...   \n",
      "11         Data analysis by web scraping using python   \n",
      "12  Conceptual approach for development of web scr...   \n",
      "13  A novel web scraping approach using the additi...   \n",
      "14     A review on web scrapping and its applications   \n",
      "15  A primer on theory-driven web scraping: Automa...   \n",
      "16                                Python Web Scraping   \n",
      "17  Cloud based web scraping for big data applicat...   \n",
      "18             Web scraping in an era of big data 2.0   \n",
      "19  Web scraping meets survey design: Combining fo...   \n",
      "20          Web scraping made simple with sitescraper   \n",
      "21                  WebSelF: A web scraping framework   \n",
      "22                        Algorithms for web scraping   \n",
      "23  Modern techniques of web scraping for data sci...   \n",
      "24                 Effective web scraping with oxpath   \n",
      "25  Web scraping in the statistics and data scienc...   \n",
      "26  Scraping the demos. Digitalization, web scrapi...   \n",
      "27                   A new common law of web scraping   \n",
      "28                                       Web scraping   \n",
      "29  Web scraping techniques to collect data on con...   \n",
      "\n",
      "                                              Authors  Cited No.  \n",
      "0                           [D Glez-Peña, A Lourenço]        242  \n",
      "1                                            [B Zhao]        155  \n",
      "2                                     [DS Sirisuriya]        105  \n",
      "3              [R Mitchell - 2018 - books.google.com]        572  \n",
      "4                                          [MA Khder]         92  \n",
      "5                [R Lawson - 2015 - books.google.com]         80  \n",
      "6                                 [V Krotov, L Silva]         91  \n",
      "7                      [V Krotov, L Johnson, L Silva]         39  \n",
      "8                       [EN Sarr, O Sall, B Birregah]        118  \n",
      "9                               [S Munzert, D Nyhuis]        281  \n",
      "10                                 [E Vargiu, M Urru]        221  \n",
      "11                                         [S Mathur]         95  \n",
      "12                                          [P Milev]         36  \n",
      "13                                           [E Uzun]         66  \n",
      "14                                  [A Mitra, S Paul]         82  \n",
      "15                            [RN Landers, RC Brusso]        211  \n",
      "16     [K Jarmul, R Lawson - 2017 - books.google.com]         26  \n",
      "17                          [RS Chaulagain, S Pandey]         70  \n",
      "18  [J Snell, N Menaldo - Bloomberg Law News, 2016...         25  \n",
      "19                                      [O ten Bosch]         20  \n",
      "20                            [T Baldwin, D Martinez]         24  \n",
      "21                  [JG Thomsen, E Ernst, C Brabrand]         16  \n",
      "22  [PH Cording, K Lyngby - … : Technical Universi...         15  \n",
      "23                            [M Gheorghe, M Dârdală]         15  \n",
      "24                 [G Grasso, T Furche, C Schallhart]         20  \n",
      "25                     [M Dogucu, M Çetinkaya-Rundel]         32  \n",
      "26                                       [L Ulbricht]         50  \n",
      "27                                        [BLW Sobel]         33  \n",
      "28  [T Bressoud, D White, T Bressoud, D White - In...          2  \n",
      "29                                         [RL Conte]         63  \n"
     ]
    }
   ],
   "source": [
    "LINKS = []\n",
    "Titles = []\n",
    "Author = []\n",
    "\n",
    "cited_numbers = []\n",
    "for i in range(3):\n",
    "    \n",
    "    url = \"https://scholar.google.com/scholar?start=\"+str(i*10)+\"&q=web+scraping&hl=en&as_sdt=0,5\"\n",
    "    Header = ({\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\"})\n",
    "#     print(url)\n",
    "    r = requests.get(url, headers = Header)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "#     print(soup)\n",
    "    links = soup.find_all(\"h3\", class_=\"gs_rt\")\n",
    "#     print(\"=======\",links)\n",
    "    for i in links:\n",
    "        link = i.find(\"a\")\n",
    "        if link:\n",
    "            href = link.get(\"href\")\n",
    "            LINKS.append(href)\n",
    "#             print(href)\n",
    "        else:\n",
    "            pass\n",
    "    print(len(LINKS))\n",
    "    \n",
    "#==============================================================\n",
    "    elements = soup.find_all('h3', class_='gs_rt')\n",
    "    \n",
    "    for element in elements:\n",
    "        a_tag = element.find('a')\n",
    "        if a_tag:\n",
    "            # Retrieve the text from the <a> tag\n",
    "            link_text = a_tag.get_text()\n",
    "            Titles.append(link_text)\n",
    "#     print(Titles)\n",
    "    print(len(Titles))\n",
    "    \n",
    "#==============================================================\n",
    "\n",
    "    div_elements = soup.find_all('div', class_='gs_a')\n",
    "    \n",
    "    for div in div_elements:\n",
    "        # Find all the <a> elements within the <div>\n",
    "        a_elements = div.find_all('a')\n",
    "\n",
    "        # Extract and print the text from the <a> elements or the text from the <div> if there are no <a> elements\n",
    "        if a_elements:\n",
    "            text = [a.get_text() for a in a_elements]\n",
    "    #         print('Text:', ', '.join(text))\n",
    "            Author.append(text)\n",
    "        else:\n",
    "            # If there are no <a> elements, extract and print the text from the <div>\n",
    "            r = [div.get_text()]\n",
    "            Author.append(r)\n",
    "#     print(len(Author))\n",
    "    print(len(Author))\n",
    "    \n",
    "    div_elements = soup.find_all(\"div\", class_=\"gs_fl gs_flb\")\n",
    "    text_list = []   \n",
    "    for div_element in div_elements:\n",
    "        a_tags = div_element.find_all(\"a\")\n",
    "        a_text_list = [a.get_text() for a in a_tags]\n",
    "        text_list.extend(a_text_list)\n",
    "#     print(lentext_list)\n",
    "    \n",
    "    import re\n",
    "\n",
    "    text_list1 = text_list\n",
    "    # Regular expression to extract \"Cited by\" number\n",
    "    pattern = r'Cited by (\\d+)'\n",
    "\n",
    "    \n",
    "    for text in text_list1:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            cited_numbers.append(int(match.group(1)))\n",
    "\n",
    "    print(len(cited_numbers))\n",
    "    df = pd.DataFrame({\"URL\":LINKS, \"Title\":Titles, \"Authors\":Author, \"Cited No.\":cited_numbers})\n",
    "#     print(df)\n",
    "print(df)\n",
    "df.index = df.index + 1    \n",
    "df.to_csv(\"E:/Project/Web-Scapping/Google-Scholar-dataset\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e49d554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
